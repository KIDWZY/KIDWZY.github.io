<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">

    

    
    <title>Python爬虫【一】requests库的使用 | TakumiWzy的博客</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="Python爬虫">
    
    <meta name="description" content="前言：上周在学习VAE（变分自编码器）和DCGAN（深度生成对抗网络）用于生成人脸图像时，发现需要大量的图片数据。包括一些特殊的人脸，二次元动漫头像之类，想要制作自己理想的喜欢的二次元妹纸图片 数据集，因此发现利用python来对一些网站图片进行爬取是最方便的！因此，相当于同时扩展一下知识面，将所用到的爬取图片的库的使用方法结合其官方的使用文档做以记录。 requests库的使用方法1.reque">
<meta name="keywords" content="Python爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫【一】requests库的使用">
<meta property="og:url" content="http://yoursite.com/2019/05/11/Python爬虫【一】requests库的使用/index.html">
<meta property="og:site_name" content="TakumiWzy的博客">
<meta property="og:description" content="前言：上周在学习VAE（变分自编码器）和DCGAN（深度生成对抗网络）用于生成人脸图像时，发现需要大量的图片数据。包括一些特殊的人脸，二次元动漫头像之类，想要制作自己理想的喜欢的二次元妹纸图片 数据集，因此发现利用python来对一些网站图片进行爬取是最方便的！因此，相当于同时扩展一下知识面，将所用到的爬取图片的库的使用方法结合其官方的使用文档做以记录。 requests库的使用方法1.reque">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-05-17T05:43:30.741Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫【一】requests库的使用">
<meta name="twitter:description" content="前言：上周在学习VAE（变分自编码器）和DCGAN（深度生成对抗网络）用于生成人脸图像时，发现需要大量的图片数据。包括一些特殊的人脸，二次元动漫头像之类，想要制作自己理想的喜欢的二次元妹纸图片 数据集，因此发现利用python来对一些网站图片进行爬取是最方便的！因此，相当于同时扩展一下知识面，将所用到的爬取图片的库的使用方法结合其官方的使用文档做以记录。 requests库的使用方法1.reque">
    

    
        <link rel="alternate" href="https://blog.csdn.net/KID_yuan" title="TakumiWzy的博客" type="application/atom+xml">
    

    
        <link rel="icon" href="/images/plane.png">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.4.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/">主页</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python爬虫/">Python爬虫</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/tf-boys-Tensorflow/">tf.boys(Tensorflow)</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/科技随想/">科技随想</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/随笔/">随笔</a></li></ul>
                                    
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/about/index.html">关于</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/Python爬虫/">Python爬虫</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-Python爬虫【一】requests库的使用" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Python爬虫【一】requests库的使用
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
      <i class="fa fa-calendar"></i>
      <a href="/2019/05/11/Python爬虫【一】requests库的使用/" class="article-date">
         <time datetime="2019-05-11T04:40:07.000Z" itemprop="datePublished">2019-05-11</time>
      </a>
    </div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/Python爬虫/">Python爬虫</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <p>前言：上周在学习VAE（变分自编码器）和DCGAN（深度生成对抗网络）用于生成人脸图像时，发现需要大量的图片数据。包括一些特殊的人脸，二次元动漫头像之类，想要制作自己理想的<del>喜欢的二次元妹纸图片</del> 数据集，因此发现利用python来对一些网站图片进行爬取是最方便的！因此，相当于同时扩展一下知识面，将所用到的爬取图片的库的使用方法结合其官方的使用文档做以记录。</p>
<h1 id="requests库的使用方法"><a href="#requests库的使用方法" class="headerlink" title="requests库的使用方法"></a>requests库的使用方法</h1><h2 id="1-requests库的安装与导入"><a href="#1-requests库的安装与导入" class="headerlink" title="1.requests库的安装与导入"></a>1.requests库的安装与导入</h2><p>windows用户电脑安装了Python后使用其包管理工具命令pip安装：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
<p>同理，若用conda则安装命令为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install requests</span><br></pre></td></tr></table></figure>
<p>其他一些额外说明和安装方式可参考中文版官方文档：</p>
<p><a href="http://cn.python-requests.org/zh_CN/latest/" target="_blank" rel="noopener">http://cn.python-requests.org/zh_CN/latest/</a></p>
<p>导入requests包：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'https://www.baidu.com/'</span>)  <span class="comment"># 向网站发送请求</span></span><br><span class="line">print(r.status_code)  <span class="comment"># 返回状态码200</span></span><br></pre></td></tr></table></figure>
<p>常见状态码与其含义：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">类别</th>
<th style="text-align:center">原因短语</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1xx</td>
<td style="text-align:center">Informational(信息性状态码)</td>
<td style="text-align:center">接受的请求正在处理</td>
</tr>
<tr>
<td style="text-align:center">2xx</td>
<td style="text-align:center">Success(成功状态码)</td>
<td style="text-align:center">请求正常处理完毕</td>
</tr>
<tr>
<td style="text-align:center">3xx</td>
<td style="text-align:center">Redirection(重定向状态码)</td>
<td style="text-align:center">需要进行附加操作以完成请求</td>
</tr>
<tr>
<td style="text-align:center">4xx</td>
<td style="text-align:center">Client Error(客户端错误状态码)</td>
<td style="text-align:center">服务器无法处理请求</td>
</tr>
<tr>
<td style="text-align:center">5xx</td>
<td style="text-align:center">Server Error(服务器错误状态码)</td>
<td style="text-align:center">服务器处理请求出错</td>
</tr>
</tbody>
</table>
<h2 id="2-为什么用requests？"><a href="#2-为什么用requests？" class="headerlink" title="2.为什么用requests？"></a>2.为什么用requests？</h2><p>requests是python的一种HTTP客户端库，与urllib,urllib2相似，虽然， python的标准库urllib2提供了大部分需要的HTTP功能，但是API的使用方法太逆天了，一个简单的功能就需要一大堆代码。因此选择requests更加方便省事。</p>
<h2 id="3-快速入门"><a href="#3-快速入门" class="headerlink" title="3.快速入门"></a>3.快速入门</h2><h3 id="3-1发送请求"><a href="#3-1发送请求" class="headerlink" title="3.1发送请求"></a>3.1发送请求</h3><p>调用方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">requests.get(url, params=<span class="literal">None</span>, **kwargs)</span><br><span class="line">说明：Sends a GET request.</span><br><span class="line">参数：url:简单理解为网站资源定位器。</span><br><span class="line">返回：<span class="keyword">return</span>: :<span class="class"><span class="keyword">class</span>:</span>`Response &lt;Response&gt;` object</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先将requests包导入</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment">#填写一个网站，使用r来接受返回的响应</span></span><br><span class="line">r = requests.get(<span class="string">'https://www.baidu.com/'</span>)  <span class="comment"># 向网站发送请求</span></span><br><span class="line"><span class="comment">#打印状态码</span></span><br><span class="line">print(r.status_code)  <span class="comment"># 返回状态码200</span></span><br></pre></td></tr></table></figure>
<p>到这里就可以使用参数r的各种方法与函数。</p>
<p>由于HTTP请求还有许多其他类型，例如：post,put,delet,head,options，都可以参考上面的方式实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#填写一个网站，使用r来接受返回的响应</span></span><br><span class="line">r = requests.post(<span class="string">'https://www.baidu.com/'</span>) </span><br><span class="line">r = requests.put(<span class="string">'https://www.baidu.com/'</span>)  </span><br><span class="line">r = requests.delet(<span class="string">'https://www.baidu.com/'</span>)  </span><br><span class="line">r = requests.head(<span class="string">'https://www.baidu.com/'</span>)  </span><br><span class="line">r = requests.option(<span class="string">'https://www.baidu.com/'</span>)</span><br></pre></td></tr></table></figure>
<p>最常用的就是get，其他的具体用到再去查询即可。</p>
<h3 id="3-2给url传递参数"><a href="#3-2给url传递参数" class="headerlink" title="3.2给url传递参数"></a>3.2给url传递参数</h3><p>即在某些url中有些特定的想查询的数据，是以键/值对形式放置在url中，具体是在一个问号的后面：<code>httpbin.org/get?key=val</code>，那么此时就可以自己设置以字典形式的关键字参数对这些参数进行传入。给出官方例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">payload = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>, <span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;</span><br><span class="line">r = requests.get(<span class="string">"http://httpbin.org/get"</span>, params=payload)</span><br><span class="line">print(r.url)<span class="comment">#打印出新的url可见自己设置的关键字参数以及被编码为新的网址</span></span><br><span class="line"><span class="comment">#输出：http://httpbin.org/get?key1=value1&amp;key2=value2</span></span><br></pre></td></tr></table></figure>
<h3 id="3-3获取响应内容"><a href="#3-3获取响应内容" class="headerlink" title="3.3获取响应内容"></a>3.3获取响应内容</h3><p><code>r.text</code>：unicode 字符集都能被无缝地解码。</p>
<p><code>r.content</code>：对于非文本请求，以字节方式获取二进制响应内容。</p>
<p><code>r.encoding</code>：返回编码方式</p>
<p><code>r.json</code>：解码JSON响应内容。</p>
<p>实例访问Bilibili：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'https://www.bilibili.com/'</span>)  <span class="comment"># 向网站发送请求,此时若</span></span><br><span class="line">print(r.status_code)  <span class="comment"># 返回状态码200</span></span><br><span class="line">print(r.text)</span><br><span class="line"><span class="comment">#输出&lt;!DOCTYPE html&gt;&lt;html lang="zh-Hans"&gt;&lt;head&gt;</span></span><br><span class="line"><span class="comment">#&lt;meta charset="utf-8"&gt;&lt;title&gt;哔哩哔哩 (゜-゜)つロ 干杯~-bilibili&lt;/title&gt;&lt;meta name=....省略....</span></span><br><span class="line">print(r.encoding)<span class="comment">#输出：utf-8</span></span><br></pre></td></tr></table></figure>
<p><code>r.raw</code>：获取来自服务器的原始套接字响应。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment">#使用r.raw方式，此时注意stream=True要设置True</span></span><br><span class="line">r = requests.get(<span class="string">'https://www.bilibili.com/'</span>,stream=<span class="literal">True</span>)  <span class="comment"># 向网站发送请求</span></span><br><span class="line">print(r.status_code)  <span class="comment"># 返回状态码200</span></span><br><span class="line">print(r.raw)<span class="comment">#输出：&lt;urllib3.response.HTTPResponse object at 0x000001BA63BEFEF0&gt;</span></span><br><span class="line">print(r.raw.read(<span class="number">6</span>))</span><br><span class="line"><span class="comment">#输出：</span></span><br><span class="line"><span class="number">200</span></span><br><span class="line">&lt;urllib3.response.HTTPResponse object at <span class="number">0x000001BA63C1AA20</span>&gt;</span><br><span class="line"><span class="string">b'\x1f\x8b\x08\x00\x00\x00'</span></span><br></pre></td></tr></table></figure>
<p>一般情况下，应该以<code>r.iter_content(chunk_size)</code>模式将文本流保存到文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> fd:</span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content(chunk_size):</span><br><span class="line">        fd.write(chunk)</span><br></pre></td></tr></table></figure>
<h3 id="3-4定制请求头部内容"><a href="#3-4定制请求头部内容" class="headerlink" title="3.4定制请求头部内容"></a>3.4定制请求头部内容</h3><p>首先通过<code>r.headers</code>来获取响应头内容。并且结果是以字典的形式返回了全部内容，我们也可以访问部分内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">'https://www.bilibili.com/'</span></span><br><span class="line">r = requests.get(url)</span><br><span class="line"><span class="comment">#打印信息</span></span><br><span class="line">print(r.request.headers[<span class="string">'User-Agent'</span>])</span><br><span class="line"><span class="comment">#输出：</span></span><br><span class="line">python-requests/<span class="number">2.21</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>
<p>伪装请求头部是采集时经常用的，我们可以用这个方法来隐藏：</p>
<p>为请求添加 HTTP 头部，只要简单地传递一个 <code>dict</code> 给 <code>headers</code> 参数就可以了。注意: 所有的 header 值必须是 string、bytestring 或者 unicode。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">'https://www.bilibili.com/'</span></span><br><span class="line"><span class="comment">#自己定义一个User-Agent头部：abcdefg123</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'abcdefg123'</span>&#125;</span><br><span class="line"><span class="comment">#将头部信息传入url参数</span></span><br><span class="line">r = requests.get(url,headers=headers)</span><br><span class="line"><span class="comment">#打印信息</span></span><br><span class="line">print(r.request.headers[<span class="string">'User-Agent'</span>])</span><br><span class="line"><span class="comment">#输出：</span></span><br><span class="line">abcdefg123</span><br></pre></td></tr></table></figure>
<h3 id="3-5设置超时时间"><a href="#3-5设置超时时间" class="headerlink" title="3.5设置超时时间"></a>3.5设置超时时间</h3><p>通常我们在爬取网站时，网站响应时间过长影响我们后续操作。因此可以通过<code>timeout</code>属性设置超时时间，一旦超过这个时间还没获得响应内容，就会提示错误。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">'https://www.bilibili.com/'</span></span><br><span class="line">r = requests.get(url,timeout=<span class="number">0.000001</span>)</span><br><span class="line"><span class="comment">#输出报错信息：</span></span><br><span class="line">ConnectTimeout: HTTPSConnectionPool(host=<span class="string">'www.bilibili.com'</span>, port=<span class="number">443</span>):....省略....</span><br></pre></td></tr></table></figure>
<h3 id="3-6代理访问"><a href="#3-6代理访问" class="headerlink" title="3.6代理访问"></a>3.6代理访问</h3><p>采集网站数据时，为避免被封IP，可以使用设置代理。requests也有相应的<code>proxies</code>属性。具体根据操作来进行设置网站。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">  <span class="string">"http"</span>: <span class="string">"http://xxxxxxxxxxxxxxx"</span>,</span><br><span class="line">  <span class="string">"https"</span>: <span class="string">"http://xxxxxxxxxxxxxxx"</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">r=requests.get(<span class="string">"http://www.bilibili.com"</span>, proxies=proxies)</span><br><span class="line">print(r.status_code)</span><br><span class="line">如果代理需要登录账户与密码：</span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">"http"</span>: <span class="string">"http://user:pass@xxxxxxxxxxx/"</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>具体用时再去查。</p>
<h3 id="3-7访问Cookie"><a href="#3-7访问Cookie" class="headerlink" title="3.7访问Cookie"></a>3.7访问Cookie</h3><p>如果某个响应中包含一些 cookie，你可以快速访问它们：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://example.com/some/cookie/setting/url'</span></span><br><span class="line">r = requests.get(url)</span><br><span class="line">print(r.cookies[<span class="string">'example_cookie_name'</span>])</span><br><span class="line"><span class="comment">#输出</span></span><br><span class="line"><span class="string">'example_cookie_value'</span></span><br></pre></td></tr></table></figure>
<p>发送你的cookies到服务器，可以使用 <code>cookies</code> 参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://httpbin.org/cookies'</span></span><br><span class="line">cookies = dict(cookies_are=<span class="string">'working'</span>)</span><br><span class="line">r = requests.get(url, cookies=cookies)</span><br><span class="line">print(r.text)</span><br><span class="line"><span class="comment">#输出</span></span><br><span class="line"><span class="string">'&#123;"cookies": &#123;"cookies_are": "working"&#125;&#125;'</span></span><br></pre></td></tr></table></figure>
<p>其实在真正用到的时候只有获取其网站请求响应就以及足够了，具体其他一些额外的高级的用法用时候结合<a href="http://cn.python-requests.org/zh_CN/latest/" target="_blank" rel="noopener">官方文档</a>再去查询。后面结合BeautifulSoup包来对网站请求的响应来进行解析也很重要。</p>
<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p><a href="http://cn.python-requests.org/zh_CN/latest/" target="_blank" rel="noopener">http://cn.python-requests.org/zh_CN/latest/</a></p>
<p><a href="https://www.cnblogs.com/derek1184405959/p/8448875.html" target="_blank" rel="noopener">https://www.cnblogs.com/derek1184405959/p/8448875.html</a></p>
<p><a href="https://www.cnblogs.com/lgh344902118/p/6780960.html" target="_blank" rel="noopener">https://www.cnblogs.com/lgh344902118/p/6780960.html</a></p>

        </div>
        <footer class="article-footer">
            



    <a data-url="http://yoursite.com/2019/05/11/Python爬虫【一】requests库的使用/" data-id="ck8y18hlq0005bwvvpdnairme" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "TakumiWzy"
        },
        "headline": "Python爬虫【一】requests库的使用",
        "image": "http://yoursite.com",
        "keywords": "Python爬虫",
        "genre": "Python爬虫",
        "datePublished": "2019-05-11",
        "dateCreated": "2019-05-11",
        "dateModified": "2019-05-17",
        "url": "http://yoursite.com/2019/05/11/Python爬虫【一】requests库的使用/",
        "description": "前言：上周在学习VAE（变分自编码器）和DCGAN（深度生成对抗网络）用于生成人脸图像时，发现需要大量的图片数据。包括一些特殊的人脸，二次元动漫头像之类，想要制作自己理想的喜欢的二次元妹纸图片 数据集，因此发现利用python来对一些网站图片进行爬取是最方便的！因此，相当于同时扩展一下知识面，将所用到的爬取图片的库的使用方法结合其官方的使用文档做以记录。
requests库的使用方法1.reque",
        "wordCount": 608
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>


    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="twitter" href="https://twitter.com/TakumiDi" target="_blank" rel="noopener">
                        <i class="icon fa fa-twitter"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/TakumiWzy" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="https://blog.csdn.net/KID_yuan" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="https://www.weibo.com/ziyuanwow" target="_blank" rel="noopener">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="tv" href="https://space.bilibili.com/25242571" target="_blank" rel="noopener">
                        <i class="icon fa fa-tv"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2019/05/11/Python爬虫【二】BeautifulSoup库的使用/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            Python爬虫【二】BeautifulSoup库的使用
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2019/05/01/复仇者联盟四观影感/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">复仇者联盟四观影感</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/05/16/科技幻想篇【三】之全息影像AI/" class="thumbnail">
    
    
        <span style="background-image:url(/images/gatebox6.gif)" alt="科技幻想篇【三】之全息影像AI" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/科技随想/">科技随想</a></p>
                            <p class="item-title"><a href="/2019/05/16/科技幻想篇【三】之全息影像AI/" class="title">科技幻想篇【三】之全息影像AI</a></p>
                            <p class="item-date"><time datetime="2019-05-16T04:35:04.000Z" itemprop="datePublished">2019-05-16</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/05/12/Python爬虫【三】静态html网页图片下载/" class="thumbnail">
    
    
        <span style="background-image:url(/images/anime1.PNG)" alt="Python爬虫【三】静态html网页图片下载" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2019/05/12/Python爬虫【三】静态html网页图片下载/" class="title">Python爬虫【三】静态html网页图片下载</a></p>
                            <p class="item-date"><time datetime="2019-05-12T03:52:30.000Z" itemprop="datePublished">2019-05-12</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/05/11/Python爬虫【二】BeautifulSoup库的使用/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2019/05/11/Python爬虫【二】BeautifulSoup库的使用/" class="title">Python爬虫【二】BeautifulSoup库的使用</a></p>
                            <p class="item-date"><time datetime="2019-05-11T04:42:44.000Z" itemprop="datePublished">2019-05-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/05/11/Python爬虫【一】requests库的使用/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python爬虫/">Python爬虫</a></p>
                            <p class="item-title"><a href="/2019/05/11/Python爬虫【一】requests库的使用/" class="title">Python爬虫【一】requests库的使用</a></p>
                            <p class="item-date"><time datetime="2019-05-11T04:40:07.000Z" itemprop="datePublished">2019-05-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/05/01/复仇者联盟四观影感/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2019/05/01/复仇者联盟四观影感/" class="title">复仇者联盟四观影感</a></p>
                            <p class="item-date"><time datetime="2019-05-01T02:04:25.000Z" itemprop="datePublished">2019-05-01</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python爬虫/">Python爬虫</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tf-boys-Tensorflow/">tf.boys(Tensorflow)</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/科技随想/">科技随想</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a><span class="category-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a><span class="archive-list-count">4</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python爬虫/">Python爬虫</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tf-boys-Tensorflow-笔记/">tf.boys(Tensorflow)笔记</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/二次元/">二次元</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/博客配置相关/">博客配置相关</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/生活感悟/">生活感悟</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/电影杂谈/">电影杂谈</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/科技宅/">科技宅</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/科研感悟/">科研感悟</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Python爬虫/" style="font-size: 15px;">Python爬虫</a> <a href="/tags/tf-boys-Tensorflow-笔记/" style="font-size: 20px;">tf.boys(Tensorflow)笔记</a> <a href="/tags/二次元/" style="font-size: 10px;">二次元</a> <a href="/tags/博客配置相关/" style="font-size: 10px;">博客配置相关</a> <a href="/tags/机器学习/" style="font-size: 10px;">机器学习</a> <a href="/tags/生活感悟/" style="font-size: 20px;">生活感悟</a> <a href="/tags/电影杂谈/" style="font-size: 10px;">电影杂谈</a> <a href="/tags/科技宅/" style="font-size: 10px;">科技宅</a> <a href="/tags/科研感悟/" style="font-size: 10px;">科研感悟</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 TakumiWzy</p>
                
                <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="https://github.com/ppoffice" target="_blank">PPOffice</a></p>
                
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hueman';
    
    
    var disqus_url = 'http://yoursite.com/2019/05/11/Python爬虫【一】requests库的使用/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    

    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"right","width":108,"height":180},"mobile":{"show":true},"log":false});</script></body>
</html>
